<!DOCTYPE html>
<html>
	<head>
    <link href="http://s3.amazonaws.com/codecademy-content/courses/ltp/css/bootstrap.css" rel="stylesheet">
	  <link type="text/css" rel="stylesheet" href="projects.css"/>

    <title> Projects </title>
  </head>


	<body>
      <img class="front-pic" src="http://previews.123rf.com/images/tommaso79/tommaso791111/tommaso79111100029/11178438-tools-and-papers-for-planning-an-architecture-project-Stock-Photo.jpg" />

  		<div class="navig">
    		<div class="button">
            <li><a href="index.html">Home</a></li>
	    <li><a href="data_science_1.html">Data Science</a></li>
	    <li><a href="notes_articles.html">Notes &amp Projects</a></li>
  	    <li><a >CV</a></li>
            <li><a href="login.html">Login</a></li>
  		  </div>
      </div>


    <div class="intro">
      <div class="text">
        <p> 
        <h4> <b>On A/B testing</b> </h4>
        A randomized controlled experiment with two variant, the treatment and control group.
        <ul><a href="http://www.win-vector.com/blog/2015/06/designing-ab-tests/">Why does designing a simple A/B test seem so complicated</a></ul> 
        </p>
      </div>
      </div>

    <div class="intro">
      <div class="text">
        <p>
        <h4> <b>Evaluating "reproducibility" using a Bayesian framework</b></h4>
        Recent reproducibility efforts for some impactful findings in psychology and biomedical research yielded some dismal
        results, with the majority of those studies failing to be replicated.<br> 
        Does the picture change when considering a more nuanced bayesian metrics, where the null hypothesis and the original study
        are compared based on which better predicts the replication result?
        <ul><a href="http://alexanderetz.com/2015/08/30/the-bayesian-reproducibility-project/">The bayesian reproducibility project</a></ul> 
      </div>
      </div>

    <div class="intro">
      <div class="text">
        <p>
        <h4> <b>A common pitfall when doing cross-validation</b></h4>
        "Knowledge leaking" is when some information from the test set is used into the model <b>before</b> the cross-validation step (e.g. 
        if a correlation observed on the test set leads to do some feature selection on the train set before doing the cross validation.
        <ul><a href="http://www.alfredo.motta.name/cross-validation-done-wrong/">Cross-validation done wrong</a></ul> 
      </div>
      </div>

    <div class="intro">
      <div class="text">
        <p>
        <h4> <b>Data science in agriculture</b></h4>
        Similar to one of the problems posed in kaggle <a href="https://www.kaggle.com/c/afsis-soil-properties">chemical soil properties from spectral measurements</a> 
        <ul><a href="http://openmarkets.cmegroup.com/9625/how-satellite-technology-is-predicting-crop-yields">Using remote-sensing satellite data to predict crops yields</a></ul> 
      </div>
      </div>

    <div class="intro">
      <div class="text">
        <p>
        <h4> <b>On the theory of causal inference</b></h4>
        Even for randomized controlled experiment, infering causality is difficult. For observational data,
        the problem of confounding variables becomes acute. Big data does not necessarily solves the problem.
        Cross-validation methods, bayesian approaches are some approaches to the issue.
        Below is an abstract mathematical look at the theory of causality.
        <ul><a href="http://www.michaelnielsen.org/ddi/if-correlation-doesnt-imply-causation-then-what-does/">If correlation does not imply causation, what does?</a></ul> 
      </div>
      </div>

  </body>
</html>






